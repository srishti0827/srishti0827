!pip install split_folders
Requirement already satisfied: split_folders in /usr/local/lib/python3.7/dist-packages (0.5.1)
%cd /content/drive/MyDrive/Colab Notebooks/ML LAB
[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/ML LAB'
/content
!ls
drive  sample_data


!unzip archive.zip
import splitfolders
splitfolders.ratio("/content/drive/MyDrive/Colab Notebooks/ML_LAB/covid_dataset/COVID", output="/content/drive/MyDrive/Colab Notebooks/ML_LAB/covid_dataset/split", seed=1337, ratio=(.8, .1, .1), group_prefix=None)
Copying files: 7232 files [01:40, 71.92 files/s]
from keras.preprocessing.image import ImageDataGenerator

# Normalize training and validation data in the range of 0 to 1
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Read the training sample and set the batch size 
train_generator = train_datagen.flow_from_directory(
        '/content/drive/MyDrive/Colab Notebooks/ML_LAB/covid_dataset/split/train/',
        target_size=(128, 128),
        batch_size=8,
        seed=100,
        class_mode='categorical')

# Read Validation data from directory and define target size with batch size
validation_generator = validation_datagen.flow_from_directory(
        '/content/drive/MyDrive/Colab Notebooks/ML_LAB/covid_dataset/split/val/',
        target_size=(128, 128),
        batch_size=8,
        class_mode='categorical',
        seed=1000,
        shuffle=False)

test_generator = test_datagen.flow_from_directory(
        '/content/drive/MyDrive/Colab Notebooks/ML_LAB/covid_dataset/split/test/',
        target_size=(128, 128),
        batch_size=8,
        seed=500,
        class_mode='categorical',
        shuffle=False)
Found 5784 images belonging to 2 classes.
Found 722 images belonging to 2 classes.
Found 726 images belonging to 2 classes.
Model building


from tensorflow import keras
from tensorflow.keras import layers
inputs = keras.Input(shape=(128, 128,3))
x = layers.Flatten()(inputs)
x = layers.Dense(32, activation="relu")(x)
x = layers.Dense(64, activation='relu')(x)
outputs = layers.Dense(3, activation="softmax")(x)
model = keras.Model(inputs, outputs)
model.summary()
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 128, 128, 3)]     0         
                                                                 
 flatten (Flatten)           (None, 49152)             0         
                                                                 
 dense (Dense)               (None, 32)                1572896   
                                                                 
 dense_1 (Dense)             (None, 64)                2112      
                                                                 
 dense_2 (Dense)             (None, 3)                 195       
                                                                 
=================================================================
Total params: 1,575,203
Trainable params: 1,575,203
Non-trainable params: 0
_________________________________________________________________


! pip install tensorflow
Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)
Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)
Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)
Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)
Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)
Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)
Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)
Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)
Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)
Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)
Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)
Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)
Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)
Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)
Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)
Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)
Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)
Collecting tf-estimator-nightly==2.8.0.dev2021122109
  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)
     |████████████████████████████████| 462 kB 8.8 MB/s 
Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)
Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)
Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)
Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)
Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)
Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)
Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)
Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)
Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)
Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)
Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)
Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)
Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)
Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)
Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)
Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)
Installing collected packages: tf-estimator-nightly
Successfully installed tf-estimator-nightly-2.8.0.dev2021122109
Model Compilation and Training

from tensorflow.keras.optimizers import Adam
adam = Adam(learning_rate=0.0001)
# We are going to use accuracy metrics and cross entropy loss as performance parameters
model.compile(adam, loss='categorical_crossentropy', metrics=['acc'])
# Train the model 
history = model.fit(train_generator, 
      steps_per_epoch=train_generator.samples/train_generator.batch_size,
      epochs=100,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples/validation_generator.batch_size,
      verbose=1)
Epoch 1/100
15/15 [==============================] - 3s 41ms/step - loss: 1.2026 - acc: 0.3750 - val_loss: 1.0798 - val_acc: 0.3333
Epoch 2/100
15/15 [==============================] - 0s 32ms/step - loss: 0.7964 - acc: 0.6417 - val_loss: 0.6724 - val_acc: 0.6667
Epoch 3/100
15/15 [==============================] - 0s 30ms/step - loss: 0.6634 - acc: 0.7000 - val_loss: 0.5862 - val_acc: 0.8000
Epoch 4/100
15/15 [==============================] - 0s 30ms/step - loss: 0.6013 - acc: 0.7667 - val_loss: 0.6914 - val_acc: 0.6667
Epoch 5/100
15/15 [==============================] - 0s 28ms/step - loss: 0.5565 - acc: 0.7417 - val_loss: 0.4563 - val_acc: 0.8667
Epoch 6/100
15/15 [==============================] - 0s 29ms/step - loss: 0.4902 - acc: 0.8083 - val_loss: 0.6879 - val_acc: 0.6000
Epoch 7/100
15/15 [==============================] - 0s 29ms/step - loss: 0.5412 - acc: 0.7833 - val_loss: 0.5254 - val_acc: 0.7333
Epoch 8/100
15/15 [==============================] - 0s 29ms/step - loss: 0.4544 - acc: 0.7667 - val_loss: 0.4091 - val_acc: 0.8667
Epoch 9/100
15/15 [==============================] - 0s 31ms/step - loss: 0.4565 - acc: 0.7917 - val_loss: 0.4116 - val_acc: 0.9333
Epoch 10/100
15/15 [==============================] - 0s 30ms/step - loss: 0.5001 - acc: 0.7750 - val_loss: 0.4492 - val_acc: 0.8667
Epoch 11/100
15/15 [==============================] - 0s 30ms/step - loss: 0.5408 - acc: 0.7417 - val_loss: 0.5005 - val_acc: 0.7333
Epoch 12/100
15/15 [==============================] - 0s 30ms/step - loss: 0.4867 - acc: 0.8083 - val_loss: 0.4599 - val_acc: 0.8000
Epoch 13/100
15/15 [==============================] - 0s 31ms/step - loss: 0.5050 - acc: 0.7667 - val_loss: 0.5786 - val_acc: 0.6667
Epoch 14/100
15/15 [==============================] - 0s 30ms/step - loss: 0.4494 - acc: 0.8000 - val_loss: 0.6135 - val_acc: 0.6000
Epoch 15/100
15/15 [==============================] - 0s 30ms/step - loss: 0.4414 - acc: 0.7917 - val_loss: 0.3632 - val_acc: 0.8000
Epoch 16/100
15/15 [==============================] - 0s 29ms/step - loss: 0.3251 - acc: 0.8833 - val_loss: 0.4909 - val_acc: 0.7333
Epoch 17/100
15/15 [==============================] - 0s 29ms/step - loss: 0.3292 - acc: 0.8750 - val_loss: 0.3748 - val_acc: 0.8667
Epoch 18/100
15/15 [==============================] - 0s 29ms/step - loss: 0.3202 - acc: 0.8667 - val_loss: 0.4202 - val_acc: 0.8000
Epoch 19/100
15/15 [==============================] - 0s 30ms/step - loss: 0.3049 - acc: 0.9083 - val_loss: 0.4221 - val_acc: 0.7333
Epoch 20/100
15/15 [==============================] - 0s 29ms/step - loss: 0.3138 - acc: 0.9083 - val_loss: 0.3458 - val_acc: 0.8667
Epoch 21/100
15/15 [==============================] - 0s 30ms/step - loss: 0.3976 - acc: 0.8250 - val_loss: 0.3230 - val_acc: 0.8667
Epoch 22/100
15/15 [==============================] - 0s 29ms/step - loss: 0.3210 - acc: 0.8917 - val_loss: 0.3048 - val_acc: 0.8667
Epoch 23/100
15/15 [==============================] - 0s 29ms/step - loss: 0.2725 - acc: 0.9333 - val_loss: 0.4119 - val_acc: 0.8000
Epoch 24/100
15/15 [==============================] - 0s 28ms/step - loss: 0.2865 - acc: 0.8917 - val_loss: 0.4191 - val_acc: 0.8667
Epoch 25/100
15/15 [==============================] - 0s 29ms/step - loss: 0.2685 - acc: 0.9167 - val_loss: 0.3612 - val_acc: 0.8000
Epoch 26/100
15/15 [==============================] - 0s 30ms/step - loss: 0.2362 - acc: 0.9333 - val_loss: 0.5277 - val_acc: 0.6667
Epoch 27/100
15/15 [==============================] - 0s 28ms/step - loss: 0.2153 - acc: 0.9333 - val_loss: 0.4773 - val_acc: 0.8000
Epoch 28/100
15/15 [==============================] - 0s 30ms/step - loss: 0.2699 - acc: 0.8917 - val_loss: 0.3834 - val_acc: 0.8000
Epoch 29/100
15/15 [==============================] - 0s 29ms/step - loss: 0.2505 - acc: 0.9000 - val_loss: 0.3482 - val_acc: 0.8667
Epoch 30/100
15/15 [==============================] - 0s 30ms/step - loss: 0.2443 - acc: 0.9167 - val_loss: 0.3678 - val_acc: 0.8000
Epoch 31/100
15/15 [==============================] - 0s 30ms/step - loss: 0.2013 - acc: 0.9083 - val_loss: 0.7189 - val_acc: 0.6000
Epoch 32/100
15/15 [==============================] - 0s 31ms/step - loss: 0.2689 - acc: 0.9250 - val_loss: 0.5823 - val_acc: 0.6667
Epoch 33/100
15/15 [==============================] - 0s 30ms/step - loss: 0.2003 - acc: 0.9583 - val_loss: 0.4669 - val_acc: 0.8000
Epoch 34/100
15/15 [==============================] - 0s 30ms/step - loss: 0.2123 - acc: 0.9333 - val_loss: 0.3891 - val_acc: 0.8000
Epoch 35/100
15/15 [==============================] - 0s 30ms/step - loss: 0.1978 - acc: 0.9500 - val_loss: 0.3320 - val_acc: 0.9333
Epoch 36/100
15/15 [==============================] - 0s 30ms/step - loss: 0.1948 - acc: 0.9500 - val_loss: 0.3309 - val_acc: 0.8667
Epoch 37/100
15/15 [==============================] - 0s 30ms/step - loss: 0.1808 - acc: 0.9417 - val_loss: 0.4338 - val_acc: 0.8667
Epoch 38/100
15/15 [==============================] - 0s 29ms/step - loss: 0.1660 - acc: 0.9500 - val_loss: 0.4283 - val_acc: 0.8667
Epoch 39/100
15/15 [==============================] - 0s 30ms/step - loss: 0.1357 - acc: 0.9833 - val_loss: 0.3017 - val_acc: 0.8667
Epoch 40/100
15/15 [==============================] - 0s 29ms/step - loss: 0.1662 - acc: 0.9583 - val_loss: 0.3651 - val_acc: 0.8667
Epoch 41/100
15/15 [==============================] - 0s 30ms/step - loss: 0.1672 - acc: 0.9417 - val_loss: 0.3572 - val_acc: 0.8000
Epoch 42/100
15/15 [==============================] - 1s 35ms/step - loss: 0.2046 - acc: 0.9417 - val_loss: 0.4913 - val_acc: 0.8000
Epoch 43/100
15/15 [==============================] - 0s 29ms/step - loss: 0.1544 - acc: 0.9583 - val_loss: 0.4152 - val_acc: 0.8000
Epoch 44/100
15/15 [==============================] - 1s 30ms/step - loss: 0.1382 - acc: 0.9750 - val_loss: 0.3749 - val_acc: 0.8667
Epoch 45/100
15/15 [==============================] - 0s 30ms/step - loss: 0.1490 - acc: 0.9583 - val_loss: 0.4343 - val_acc: 0.8000
Epoch 46/100
15/15 [==============================] - 0s 29ms/step - loss: 0.1410 - acc: 0.9583 - val_loss: 0.6012 - val_acc: 0.7333
Epoch 47/100
15/15 [==============================] - 0s 30ms/step - loss: 0.1270 - acc: 0.9750 - val_loss: 0.4832 - val_acc: 0.8000
Epoch 48/100
15/15 [==============================] - 0s 29ms/step - loss: 0.1111 - acc: 0.9750 - val_loss: 0.4172 - val_acc: 0.8667
Epoch 49/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0921 - acc: 0.9917 - val_loss: 0.3326 - val_acc: 0.8667
Epoch 50/100
15/15 [==============================] - 0s 29ms/step - loss: 0.1578 - acc: 0.9417 - val_loss: 0.4585 - val_acc: 0.8000
Epoch 51/100
15/15 [==============================] - 0s 31ms/step - loss: 0.1345 - acc: 0.9417 - val_loss: 0.5868 - val_acc: 0.6667
Epoch 52/100
15/15 [==============================] - 0s 29ms/step - loss: 0.2161 - acc: 0.9167 - val_loss: 0.5806 - val_acc: 0.6000
Epoch 53/100
15/15 [==============================] - 0s 32ms/step - loss: 0.1152 - acc: 0.9667 - val_loss: 0.3669 - val_acc: 0.8667
Epoch 54/100
15/15 [==============================] - 0s 30ms/step - loss: 0.1003 - acc: 0.9917 - val_loss: 0.3729 - val_acc: 0.8667
Epoch 55/100
15/15 [==============================] - 0s 29ms/step - loss: 0.1132 - acc: 0.9667 - val_loss: 0.4298 - val_acc: 0.8667
Epoch 56/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0876 - acc: 0.9917 - val_loss: 0.5123 - val_acc: 0.8000
Epoch 57/100
15/15 [==============================] - 0s 31ms/step - loss: 0.0918 - acc: 0.9917 - val_loss: 0.4784 - val_acc: 0.8000
Epoch 58/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0786 - acc: 0.9917 - val_loss: 0.4015 - val_acc: 0.8667
Epoch 59/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0885 - acc: 0.9917 - val_loss: 0.4056 - val_acc: 0.8667
Epoch 60/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0698 - acc: 1.0000 - val_loss: 0.4685 - val_acc: 0.8000
Epoch 61/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0711 - acc: 0.9917 - val_loss: 0.4399 - val_acc: 0.8667
Epoch 62/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0734 - acc: 0.9917 - val_loss: 0.4150 - val_acc: 0.8667
Epoch 63/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0884 - acc: 0.9750 - val_loss: 0.4195 - val_acc: 0.8667
Epoch 64/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0614 - acc: 0.9917 - val_loss: 0.3794 - val_acc: 0.8667
Epoch 65/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0653 - acc: 0.9917 - val_loss: 0.5034 - val_acc: 0.8000
Epoch 66/100
15/15 [==============================] - 0s 31ms/step - loss: 0.0727 - acc: 1.0000 - val_loss: 0.8095 - val_acc: 0.6000
Epoch 67/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0765 - acc: 1.0000 - val_loss: 0.4612 - val_acc: 0.8667
Epoch 68/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0545 - acc: 0.9917 - val_loss: 0.3095 - val_acc: 0.8667
Epoch 69/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0714 - acc: 0.9917 - val_loss: 0.4526 - val_acc: 0.8667
Epoch 70/100
15/15 [==============================] - 0s 31ms/step - loss: 0.0755 - acc: 0.9833 - val_loss: 0.3443 - val_acc: 0.8667
Epoch 71/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0475 - acc: 0.9917 - val_loss: 0.4918 - val_acc: 0.8000
Epoch 72/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0576 - acc: 1.0000 - val_loss: 0.4593 - val_acc: 0.8667
Epoch 73/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0720 - acc: 0.9917 - val_loss: 0.5732 - val_acc: 0.8000
Epoch 74/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0619 - acc: 0.9917 - val_loss: 0.5120 - val_acc: 0.8000
Epoch 75/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0489 - acc: 1.0000 - val_loss: 0.3405 - val_acc: 0.8667
Epoch 76/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0552 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8000
Epoch 77/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0442 - acc: 1.0000 - val_loss: 0.3748 - val_acc: 0.8667
Epoch 78/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0517 - acc: 0.9917 - val_loss: 0.3934 - val_acc: 0.7333
Epoch 79/100
15/15 [==============================] - 0s 31ms/step - loss: 0.0673 - acc: 1.0000 - val_loss: 0.3429 - val_acc: 0.8667
Epoch 80/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0425 - acc: 1.0000 - val_loss: 0.5025 - val_acc: 0.8000
Epoch 81/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0350 - acc: 1.0000 - val_loss: 0.4649 - val_acc: 0.8000
Epoch 82/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.3942 - val_acc: 0.8667
Epoch 83/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.8000
Epoch 84/100
15/15 [==============================] - 0s 31ms/step - loss: 0.0515 - acc: 0.9917 - val_loss: 0.5261 - val_acc: 0.8000
Epoch 85/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0336 - acc: 1.0000 - val_loss: 0.5696 - val_acc: 0.8000
Epoch 86/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0387 - acc: 0.9917 - val_loss: 0.4670 - val_acc: 0.8667
Epoch 87/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.6391 - val_acc: 0.7333
Epoch 88/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0722 - acc: 0.9833 - val_loss: 0.5294 - val_acc: 0.7333
Epoch 89/100
15/15 [==============================] - 0s 32ms/step - loss: 0.0894 - acc: 0.9667 - val_loss: 0.5062 - val_acc: 0.8000
Epoch 90/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0857 - acc: 0.9667 - val_loss: 0.7343 - val_acc: 0.7333
Epoch 91/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0796 - acc: 0.9750 - val_loss: 0.5720 - val_acc: 0.8000
Epoch 92/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0429 - acc: 0.9917 - val_loss: 0.4411 - val_acc: 0.8667
Epoch 93/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.4027 - val_acc: 0.8000
Epoch 94/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8667
Epoch 95/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.4508 - val_acc: 0.8667
Epoch 96/100
15/15 [==============================] - 0s 32ms/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.5164 - val_acc: 0.8000
Epoch 97/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.3893 - val_acc: 0.8000
Epoch 98/100
15/15 [==============================] - 0s 31ms/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.4605 - val_acc: 0.8000
Epoch 99/100
15/15 [==============================] - 0s 29ms/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.4196 - val_acc: 0.8000
Epoch 100/100
15/15 [==============================] - 0s 30ms/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.7233 - val_acc: 0.7333
model.save('covid_classification.h5')
10. Model loading

from tensorflow.keras import models
model = models.load_model('covid_classification.h5')
11. Model weights saving

model.save_weights('covid_classification_weights.h5')
12. Model weights loading

model.load_weights('covid_classification_weights.h5')
13. Plotting accuracy and loss graph for training and validation dataset

train_acc = history.history['acc']
val_acc = history.history['val_acc']
train_loss = history.history['loss']
val_loss = history.history['val_loss']
import matplotlib.pyplot as plt
epochs = range(len(train_acc)) 
plt.plot(epochs, train_acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.figure()
plt.show()

plt.plot(epochs, train_loss, 'b', label='Training Loss')
plt.plot(epochs, val_loss, 'r', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

<Figure size 432x288 with 0 Axes>

14. Evaluate model performance on test dataset

test_output= model.evaluate(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)
print(test_output)
print(model.metrics_names)
1/1 [==============================] - 0s 28ms/step - loss: 0.9602 - acc: 0.8000
[0.9601898193359375, 0.800000011920929]
['loss', 'acc']
